{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021_01\n",
      "0\n",
      "2021_02\n",
      "10369174\n",
      "2021_03\n",
      "18663432\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m11\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m fname \u001b[38;5;241m==\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m fname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m13\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m fname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m14\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m fname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m15\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     18\u001b[0m     dfDets \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(f)\n\u001b[1;32m---> 19\u001b[0m     totDf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([totDf,dfDets], ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:287\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03malong the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    275\u001b[0m     objs,\n\u001b[0;32m    276\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    285\u001b[0m )\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:502\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mreindex(new_labels)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    500\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 502\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_block_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[0;32m    506\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\concat.py:69\u001b[0m, in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     66\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m---> 69\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals)\n",
      "File \u001b[1;32mc:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py:180\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m             \u001b[38;5;66;03m# coerce to object\u001b[39;00m\n\u001b[0;32m    178\u001b[0m             to_concat \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat]\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "important_cols = [\"Tweet_ID\", \"Hastag\"]\n",
    "path = \"D:\\\\CovidTweets\\\\COVID19_Tweets_Dataset_2021\\\\Summary_Hashtag\"\n",
    "outputFile = 'Hashtag.csv'\n",
    "\n",
    "totDf = pd.DataFrame()\n",
    "for file in os.listdir(path):\n",
    "    dfDets = pd.DataFrame()\n",
    "    dfSent = pd.DataFrame()\n",
    "    d = os.path.join(path, file)\n",
    "    if os.path.isdir(d):\n",
    "        print(file)\n",
    "        print(len(totDf))\n",
    "        all_files = glob.glob(os.path.join(d, \"*.csv\"))\n",
    "        for f in all_files:\n",
    "            if(os.path.exists(f)):\n",
    "                fname = f.split('\\\\')[-1].split(\"_\")[3]\n",
    "                if fname == \"11\" or fname ==  \"12\" or fname == \"13\" or fname == \"14\" or fname == \"15\":\n",
    "                    dfDets = pd.read_csv(f)\n",
    "                    dfDets['Hastag'] = dfDets['Hastag'].str.lower()\n",
    "                    dfDets = dfDets[dfDets[\"Hastag\"] == '#covid19']\n",
    "                    totDf = pd.concat([totDf,dfDets], ignore_index = True)\n",
    "#totDf.to_csv(outputFile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsPerFile = 100 ## if not given(-1), use the whole file rather than a sample\n",
    "important_cols = [\"Tweet_ID\", \"Date Created\", \"Sentiment_Label\", \"Logits_Neutral\", \"Logits_Positive\", \"Logits_Negative\"]\n",
    "path = \"D:\\\\CovidTweets\\\\COVID19_Tweets_Dataset_2021\\\\Summary_Details\"\n",
    "outputFile = 'peaktweets.csv'\n",
    "hashtags = pd.read_csv(\"Hashtag.csv\")\n",
    "tagSet = set(hashtags['Tweet_ID'])\n",
    "\n",
    "totDf = pd.DataFrame()\n",
    "for file in os.listdir(path):\n",
    "    dfDets = pd.DataFrame()\n",
    "    dfSent = pd.DataFrame()\n",
    "    d = os.path.join(path, file)\n",
    "    if os.path.isdir(d):\n",
    "        print(file)\n",
    "        print(len(totDf))\n",
    "        all_files = glob.glob(os.path.join(d, \"*.csv\"))\n",
    "        for f in all_files:\n",
    "            nuF = f.replace('Details','Sentiment')\n",
    "            if(os.path.exists(nuF)):\n",
    "                fname = f.split('\\\\')[-1].split(\"_\")[3]\n",
    "                if fname == \"11\" or fname ==  \"12\" or fname == \"13\" or fname == \"14\" or fname == \"15\":\n",
    "                    dfDets = pd.read_csv(f)\n",
    "                    dfDets = dfDets[dfDets['Tweet_ID'].isin(tagSet)]\n",
    "                    if len(dfDets[dfDets[\"Language\"] == 'en']) > rowsPerFile:\n",
    "                        rowsToTake = rowsPerFile\n",
    "                    else:\n",
    "                        rowsToTake = len(dfDets[dfDets[\"Language\"] == 'en']) \n",
    "                    if rowsPerFile != -1:\n",
    "                        dfDets = dfDets[dfDets[\"Language\"] == 'en'].sample(n=rowsToTake, random_state=42)\n",
    "                    dfSent = pd.read_csv(nuF)\n",
    "                    totDf = pd.concat([totDf,pd.merge(dfDets,dfSent, how = 'inner',on='Tweet_ID')[important_cols]], ignore_index = True)\n",
    "totDf.to_csv(outputFile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
